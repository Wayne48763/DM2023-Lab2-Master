{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "To observe the data, we first load the data and plot as bar chart.\n",
    "\n",
    "![emotion_distribution](img/emotion_dist.svg)\n",
    "\n",
    "As the plot above shows, the data is pretty imbalanced. So I downsample the data to make it more balanced.\n",
    "The downsampled data is shown below.\n",
    "\n",
    "![emotion_distribution_unbias](img/emotion_dist_unbias.svg)\n",
    "\n",
    "As the plot above shows, I downsampled the class other than `anger`, so the other classes has the same number of samples as `anger`. Since the `anger` has almost 40000 samples, I think this amount of data is enough for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "I did not do any feature extraction, because I think the model has the ability to understand the data and extract the features by itself. Feature extraction may be useful when the data is not enough for training, but in this case, I think it is not necessary.</br>\n",
    "\n",
    "I did think adding the `Hashtag` to the text, but I than found that the `Hashtag` is already included in the text, and even has its own place in the text. So I did not add the `Hashtag`, which may only disturb the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "I use RoBERTa as the model, because it is proved to be a good model for text classification. It has outperformed other machine learning models like SVM and Naive Bayes, and has better performance than other deep learning models like LSTM and CNN. So I think it is a good choice for this task.\n",
    "\n",
    "I have tried several pretrained models, including `cardiffnlp/twitter-roberta-base-2022-154m` and `cardiffnlp/twitter-roberta-base-emotion-latest`. The training data of these two models are similar to the data we use, so I think they are good choices. The latter one was specially trained for emotion classification, but"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
